{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a84c325d-2d81-43e1-aff8-0a20056db35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-11-14T11:56:53.720323+00:00] âœ… Configured Wordle listener â†’ ws://localhost:2025\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime, UTC\n",
    "\n",
    "import websockets\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# --- Configuration ---\n",
    "WS_URL = \"ws://localhost:2025\"   # ðŸ” replace with actual URL\n",
    "CONNECT_TIMEOUT = 10             # seconds to wait when opening\n",
    "RECV_TIMEOUT = 2                 # timeout per recv loop iteration\n",
    "KEEP_ALIVE = True                # keep connection open between messages\n",
    "\n",
    "load_dotenv()\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    print(f\"[{datetime.now(UTC).isoformat()}] âš ï¸ OPENAI_API_KEY was not found in the environment.\")\n",
    "\n",
    "\n",
    "def ts() -> str:\n",
    "    \"\"\"Return a short UTC timestamp for log lines.\"\"\"\n",
    "    return datetime.now(UTC).strftime(\"%H:%M:%S\")\n",
    "\n",
    "\n",
    "print(f\"[{datetime.now(UTC).isoformat()}] âœ… Configured Wordle listener â†’ {WS_URL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5e50bcc-c993-497a-bd53-d9e60d69a827",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List, Optional\n",
    "\n",
    "def map_wordle_feedback_token(token: str) -> str:\n",
    "    cleaned = str(token).strip().lower()\n",
    "    if cleaned in {\"correct\", \"green\", \"g\"}:\n",
    "        return \"correct\"\n",
    "    if cleaned in {\"present\", \"yellow\", \"y\"}:\n",
    "        return \"present\"\n",
    "    return \"absent\"\n",
    "\n",
    "@dataclass\n",
    "class ParsedMessage:\n",
    "    raw: str\n",
    "    type: Optional[str]\n",
    "    command: Optional[str]\n",
    "    match_id: Optional[str]\n",
    "    game_id: Optional[str]\n",
    "    your_id: Optional[str]\n",
    "    otp: Optional[str]\n",
    "    word_length: Optional[int]\n",
    "    max_attempts: Optional[int]\n",
    "    last_guess: str\n",
    "    last_result: List[str]\n",
    "    current_attempt: Optional[int]\n",
    "    ack_for: Optional[str]\n",
    "    ack_data: Optional[str]\n",
    "    result: Optional[str]\n",
    "    word: Optional[str]\n",
    "\n",
    "def parse_message(text: str) -> Optional[ParsedMessage]:\n",
    "    \"\"\"Return a ParsedMessage with only the fields the bot actually needs.\"\"\"\n",
    "    try:\n",
    "        obj = json.loads(text)\n",
    "    except json.JSONDecodeError:\n",
    "        return None\n",
    "\n",
    "    last_guess = obj.get(\"lastGuess\") or \"\"\n",
    "    raw_result = obj.get(\"lastResult\") or []\n",
    "    if isinstance(raw_result, list):\n",
    "        normalized = [map_wordle_feedback_token(s) for s in raw_result]\n",
    "    else:\n",
    "        normalized = []\n",
    "\n",
    "    return ParsedMessage(\n",
    "        raw=text,\n",
    "        type=obj.get(\"type\"),\n",
    "        command=obj.get(\"command\"),\n",
    "        match_id=obj.get(\"matchId\"),\n",
    "        game_id=obj.get(\"gameId\"),\n",
    "        your_id=obj.get(\"yourId\"),\n",
    "        otp=obj.get(\"otp\"),\n",
    "        word_length=obj.get(\"wordLength\"),\n",
    "        max_attempts=obj.get(\"maxAttempts\"),\n",
    "        last_guess=last_guess,\n",
    "        last_result=normalized,\n",
    "        current_attempt=obj.get(\"currentAttempt\"),\n",
    "        ack_for=obj.get(\"ackFor\"),\n",
    "        ack_data=obj.get(\"ackData\"),\n",
    "        result=obj.get(\"result\"),\n",
    "        word=obj.get(\"word\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335bb5e2",
   "metadata": {},
   "source": [
    "### OpenAI Models\n",
    "- OpenAI models evolve quickly, and understanding their capabilities helps you balance accuracy, latency, and cost.\n",
    "- Reviewing model pricing and use-case fit up front keeps you from exhausting your budget on the wrong tier.\n",
    "- Learn more about token limits, model selection tips, and deployment guides in [OpenAI Bytes](https://spl.solitontech.ai/docs/learning/openai-bytes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "90114158-165e-4de8-86bd-b6f65d05cd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "AI_MODEL = \"gpt-5-nano\"          # specify the AI model to use, switch it up and have fun\n",
    "USE_STRUCTURED_OUTPUT = True  # toggle between structured vs plain LLM guesses\n",
    "\n",
    "\n",
    "class GuessWord(BaseModel):\n",
    "    guess: str\n",
    "\n",
    "\n",
    "_ai_client: Optional[OpenAI] = None\n",
    "\n",
    "\n",
    "def _get_client() -> Optional[OpenAI]:\n",
    "    \"\"\"Lazy-load the OpenAI client so the notebook only instantiates it when needed.\"\"\"\n",
    "    global _ai_client\n",
    "    if _ai_client is None:\n",
    "        api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        if not api_key:\n",
    "            print(f\"[{ts()}] âš ï¸ OPENAI_API_KEY is not set. Skipping AI client initialization.\")\n",
    "            return None\n",
    "        _ai_client = OpenAI(api_key=api_key)\n",
    "    return _ai_client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4e38a0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def _extract_guess_text(response) -> str:\n",
    "    text_parts: List[str] = []\n",
    "    for item in getattr(response, \"output\", []):\n",
    "        if getattr(item, \"type\", \"\") != \"message\":\n",
    "            continue\n",
    "        for content in getattr(item, \"content\", []):\n",
    "            if getattr(content, \"type\", \"\") == \"output_text\":\n",
    "                text_parts.append(getattr(content, \"text\", \"\"))\n",
    "    return \" \".join(text_parts).strip()\n",
    "\n",
    "\n",
    "def _log_token_usage(response) -> None:\n",
    "    usage = getattr(response, \"usage\", None)\n",
    "    if not usage:\n",
    "        return\n",
    "\n",
    "    if isinstance(usage, dict):\n",
    "        input_tokens = usage.get(\"input_tokens\")\n",
    "        output_tokens = usage.get(\"output_tokens\")\n",
    "    else:\n",
    "        input_tokens = getattr(usage, \"input_tokens\", None)\n",
    "        output_tokens = getattr(usage, \"output_tokens\", None)\n",
    "\n",
    "    if input_tokens is None and output_tokens is None:\n",
    "        return\n",
    "\n",
    "    print(f\"[{ts()}] ðŸ“Š Token usage â€” input: {input_tokens} â€¢ output: {output_tokens}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d143515",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def _ai_guess_simple(length: int) -> Optional[str]:\n",
    "    \"\"\"Ask the model for the next guess using plain text responses.\"\"\"\n",
    "    client = _get_client()\n",
    "    if client is None:\n",
    "        return None\n",
    "\n",
    "    # system prompt sets the long-lived assistant role (tone & mission)\n",
    "    system_prompt = \"You are playing a game.\"\n",
    "    # user prompt delivers the turn-specific instruction\n",
    "    user_prompt = f\"Return only one lowercase {length}-letter guess.\"\n",
    "    try:\n",
    "        response = client.responses.create(\n",
    "            model=AI_MODEL,\n",
    "            input=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": system_prompt,\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": user_prompt,\n",
    "                },\n",
    "            ],\n",
    "            reasoning={ \"effort\": \"low\" },\n",
    "            text={ \"verbosity\": \"low\" },\n",
    "        )\n",
    "    except Exception as exc:\n",
    "        print(f\"[{ts()}] âš ï¸ AI guess failed: {exc}\")\n",
    "        return None\n",
    "\n",
    "    _log_token_usage(response)\n",
    "\n",
    "    raw_text = _extract_guess_text(response)\n",
    "    guess = raw_text.split()[0].lower() if raw_text else \"\"\n",
    "\n",
    "    if not guess:\n",
    "        print(f\"[{ts()}] âš ï¸ AI response was empty; falling back to deterministic guess.\")\n",
    "        return None\n",
    "    return guess\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340e01e9",
   "metadata": {},
   "source": [
    "### Structured Responses for Guesses\n",
    "\n",
    "- OpenAI models can return structured JSON so our bot stays on script every turn.\n",
    "- By pairing the Responses `parse` helper with a lightweight Pydantic model, we guarantee each reply includes a next guess plus a concept refresherâ€”perfect for mission debriefs and quick debugging.\n",
    "\n",
    "**Why Structured Output Matters**\n",
    "- Keeps responses machine-readable, preventing brittle string parsing in the bot.\n",
    "- Reduces hallucinated formats, so automations stay resilient even with generative models.\n",
    "- Enables guardrails and validation paths to catch malformed payloads before they impact gameplay.\n",
    "- Makes telemetry and iteration straightforward because every turn produces comparable data.\n",
    "\n",
    "Learn more about [Structured Outputs in OpenAI](https://platform.openai.com/docs/guides/structured-outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "60a0734f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _ai_guess_structured(length: int) -> Optional[str]:\n",
    "    \"\"\"Ask the model for the next guess using structured output parsing.\"\"\"\n",
    "    client = _get_client()\n",
    "    if client is None:\n",
    "        return None\n",
    "\n",
    "    prompt = f\"Return only one lowercase {length}-letter guess.\"\n",
    "    system_prompt = \"You are playing a game.\"\n",
    "    try:\n",
    "        response = client.responses.parse(\n",
    "            model=AI_MODEL,\n",
    "            input=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": system_prompt,\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt,\n",
    "                },\n",
    "            ],\n",
    "            reasoning={ \"effort\": \"low\" },\n",
    "            text={ \"verbosity\": \"low\" },\n",
    "            text_format=GuessWord,\n",
    "        )\n",
    "    except Exception as exc:\n",
    "        print(f\"[{ts()}] âš ï¸ AI guess failed: {exc}\")\n",
    "        return None\n",
    "\n",
    "    _log_token_usage(response)\n",
    "\n",
    "    parsed_payload = getattr(response, \"output_parsed\", None)\n",
    "    if not parsed_payload:\n",
    "        print(f\"[{ts()}] âš ï¸ AI response returned no payload; switching to fallback.\")\n",
    "        return None\n",
    "\n",
    "    guess = parsed_payload.guess.strip().lower()\n",
    "\n",
    "    if not guess:\n",
    "        print(f\"[{ts()}] âš ï¸ AI response was empty; falling back to deterministic guess.\")\n",
    "        return None\n",
    "    return guess\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "852d711f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _ai_guess(length: int) -> Optional[str]:\n",
    "    if USE_STRUCTURED_OUTPUT:\n",
    "        return _ai_guess_structured(length)\n",
    "    return _ai_guess_simple(length)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "faaf2f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_guess(parsed: ParsedMessage) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Use OpenAI to choose the next guess while learning from prior feedback.\n",
    "    \"\"\"\n",
    "    if parsed.command != \"guess\":\n",
    "        return None\n",
    "\n",
    "    length = parsed.word_length or 5\n",
    "    guess = _ai_guess(length)\n",
    "    if guess:\n",
    "        return guess\n",
    "\n",
    "    alphabet = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "    fallback = alphabet[:length]\n",
    "    print(f\"[{ts()}] âœ³ï¸ Using alphabet fallback guess: {fallback}\")\n",
    "    return fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ef520220-54df-4c10-881e-d597230fbcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "def build_response(parsed: ParsedMessage, guess: Optional[str]) -> Optional[dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Frames the response in the expected shape for a guess command.\n",
    "    Expected fields (from prior examples): matchId, gameId, otp, guess\n",
    "    If any critical field is missing, return None (we won't send).\n",
    "    \"\"\"\n",
    "    if parsed.command != \"guess\" or not guess:\n",
    "        return None\n",
    "\n",
    "    if not parsed.match_id or not parsed.game_id or not parsed.otp:\n",
    "        # We need these to respond correctly\n",
    "        return None\n",
    "\n",
    "    return {\n",
    "        \"matchId\": parsed.match_id,\n",
    "        \"gameId\": parsed.game_id,\n",
    "        \"otp\": parsed.otp,\n",
    "        \"guess\": guess,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bfcc54ff-742f-4687-9e29-054bcb70c1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def connect_parse_respond_forever():\n",
    "    print(f\"[{ts()}] ðŸ”Œ Connecting to {WS_URL} ...\")\n",
    "    try:\n",
    "        async with websockets.connect(WS_URL, open_timeout=CONNECT_TIMEOUT) as ws:\n",
    "            print(f\"[{ts()}] âœ… Connection established.\")\n",
    "            print(\n",
    "                f\"[{ts()}] ðŸ‘‚ Listening for guess commands only (timeout={RECV_TIMEOUT}s).\"\n",
    "            )\n",
    "\n",
    "            while True:\n",
    "                try:\n",
    "                    msg = await asyncio.wait_for(ws.recv(), timeout=RECV_TIMEOUT)\n",
    "\n",
    "                    parsed = parse_message(msg)\n",
    "                    if parsed is None:\n",
    "                        print(f\"[{ts()}] âš ï¸ Incoming text was not JSON; ignoring.\")\n",
    "                        continue\n",
    "\n",
    "                    if parsed.type == \"game result\":\n",
    "                        outcome = parsed.result or \"no outcome provided\"\n",
    "                        correct_word = parsed.word\n",
    "                        print(f\"[{ts()}] ðŸŽ¯ Game result : {outcome}. Correct Word: {correct_word}\")\n",
    "                        continue\n",
    "\n",
    "                    # print(f\"[{ts()}] ðŸ“ Parsed message: {parsed}\")\n",
    "                    guess = make_guess(parsed)\n",
    "                    if guess:\n",
    "                        print(f\"[{ts()}] ðŸ§  Proposed guess: {guess}\")\n",
    "\n",
    "                    resp = build_response(parsed, guess)\n",
    "                    if resp:\n",
    "                        await ws.send(json.dumps(resp))\n",
    "                        # print(f\"[{ts()}] ðŸ“¤ Sent guess response: {resp}\")\n",
    "\n",
    "                except asyncio.TimeoutError:\n",
    "                    if KEEP_ALIVE:\n",
    "                        continue\n",
    "                    print(\n",
    "                        f\"[{ts()}] â¹ï¸ No messages within {RECV_TIMEOUT}s; closing connection.\"\n",
    "                    )\n",
    "                    break\n",
    "                except websockets.exceptions.ConnectionClosedOK:\n",
    "                    print(f\"[{ts()}] ðŸ”’ Connection closed by server (OK).\")\n",
    "                    break\n",
    "                except websockets.exceptions.ConnectionClosedError as e:\n",
    "                    print(f\"[{ts()}] âŒ Connection closed with error: {e}\")\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    print(f\"[{ts()}] âš ï¸ Unexpected error while listening: {e}\")\n",
    "                    break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[{ts()}] âŒ Connection failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "63449ac4-55e7-4537-af06-c2431de0389c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:19:11] ðŸ”Œ Connecting to ws://localhost:2025 ...\n",
      "[12:19:13] âœ… Connection established.\n",
      "[12:19:13] ðŸ‘‚ Listening for guess commands only (timeout=2s).\n",
      "[12:23:21] ðŸ“Š Token usage â€” input: 56 â€¢ output: 144\n",
      "[12:23:21] ðŸ§  Proposed guess: crane\n",
      "[12:23:53] ðŸ“Š Token usage â€” input: 56 â€¢ output: 79\n",
      "[12:23:53] ðŸ§  Proposed guess: plant\n",
      "[12:23:56] ðŸ“Š Token usage â€” input: 56 â€¢ output: 144\n",
      "[12:23:56] ðŸ§  Proposed guess: crane\n",
      "[12:23:58] ðŸ“Š Token usage â€” input: 56 â€¢ output: 208\n",
      "[12:23:58] ðŸ§  Proposed guess: crane\n",
      "[12:24:01] ðŸ“Š Token usage â€” input: 56 â€¢ output: 144\n",
      "[12:24:01] ðŸ§  Proposed guess: crane\n",
      "[12:24:34] ðŸ“Š Token usage â€” input: 56 â€¢ output: 80\n",
      "[12:24:34] ðŸ§  Proposed guess: crane\n",
      "[12:24:37] ðŸ“Š Token usage â€” input: 56 â€¢ output: 144\n",
      "[12:24:37] ðŸ§  Proposed guess: crane\n",
      "[12:24:39] ðŸ“Š Token usage â€” input: 56 â€¢ output: 144\n",
      "[12:24:39] ðŸ§  Proposed guess: crane\n",
      "[12:24:41] ðŸ“Š Token usage â€” input: 56 â€¢ output: 144\n",
      "[12:24:41] ðŸ§  Proposed guess: crane\n",
      "[12:24:44] ðŸ“Š Token usage â€” input: 56 â€¢ output: 144\n",
      "[12:24:44] ðŸ§  Proposed guess: crane\n",
      "[12:24:46] ðŸ“Š Token usage â€” input: 56 â€¢ output: 79\n",
      "[12:24:46] ðŸ§  Proposed guess: apple\n",
      "[12:24:48] ðŸ“Š Token usage â€” input: 56 â€¢ output: 144\n",
      "[12:24:48] ðŸ§  Proposed guess: crane\n",
      "[12:24:48] ðŸŽ¯ Game result : lost. Correct Word: INGLE\n",
      "[12:24:49] ðŸŽ¯ Game result : lost. Correct Word: STEPS\n",
      "[12:25:34] ðŸ“Š Token usage â€” input: 56 â€¢ output: 208\n",
      "[12:25:34] ðŸ§  Proposed guess: crane\n",
      "[12:25:36] ðŸ“Š Token usage â€” input: 56 â€¢ output: 144\n",
      "[12:25:36] ðŸ§  Proposed guess: crane\n",
      "[12:25:40] ðŸ“Š Token usage â€” input: 56 â€¢ output: 80\n",
      "[12:25:40] ðŸ§  Proposed guess: crane\n",
      "[12:25:42] ðŸ“Š Token usage â€” input: 56 â€¢ output: 80\n",
      "[12:25:42] ðŸ§  Proposed guess: crane\n",
      "[12:25:44] ðŸ“Š Token usage â€” input: 56 â€¢ output: 80\n",
      "[12:25:44] ðŸ§  Proposed guess: slate\n",
      "[12:25:46] ðŸ“Š Token usage â€” input: 56 â€¢ output: 79\n",
      "[12:25:46] ðŸ§  Proposed guess: hello\n",
      "[12:25:48] ðŸ“Š Token usage â€” input: 56 â€¢ output: 80\n",
      "[12:25:48] ðŸ§  Proposed guess: crane\n",
      "[12:25:51] ðŸ“Š Token usage â€” input: 56 â€¢ output: 80\n",
      "[12:25:51] ðŸ§  Proposed guess: crane\n",
      "[12:25:53] ðŸ“Š Token usage â€” input: 56 â€¢ output: 80\n",
      "[12:25:53] ðŸ§  Proposed guess: crane\n",
      "[12:25:56] ðŸ“Š Token usage â€” input: 56 â€¢ output: 144\n",
      "[12:25:56] ðŸ§  Proposed guess: crane\n",
      "[12:25:58] ðŸ“Š Token usage â€” input: 56 â€¢ output: 80\n",
      "[12:25:58] ðŸ§  Proposed guess: crane\n",
      "[12:26:00] ðŸ“Š Token usage â€” input: 56 â€¢ output: 144\n",
      "[12:26:00] ðŸ§  Proposed guess: crane\n",
      "[12:26:00] ðŸŽ¯ Game result : lost. Correct Word: BUDGE\n",
      "[12:26:02] ðŸŽ¯ Game result : lost. Correct Word: QUALY\n",
      "[12:26:31] ðŸ“Š Token usage â€” input: 56 â€¢ output: 79\n",
      "[12:26:31] ðŸ§  Proposed guess: apple\n",
      "[12:26:33] ðŸ“Š Token usage â€” input: 56 â€¢ output: 144\n",
      "[12:26:33] ðŸ§  Proposed guess: crane\n",
      "[12:26:36] ðŸ“Š Token usage â€” input: 56 â€¢ output: 144\n",
      "[12:26:36] ðŸ§  Proposed guess: crane\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCancelledError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Run it (infinite loop until you interrupt the cell)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m connect_parse_respond_forever()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mconnect_parse_respond_forever\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m         msg = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.wait_for(ws.recv(), timeout=RECV_TIMEOUT)\n\u001b[32m     14\u001b[39m         parsed = parse_message(msg)\n\u001b[32m     15\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.11-windows-x86_64-none\\Lib\\asyncio\\tasks.py:520\u001b[39m, in \u001b[36mwait_for\u001b[39m\u001b[34m(fut, timeout)\u001b[39m\n\u001b[32m    517\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m    519\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m timeouts.timeout(timeout):\n\u001b[32m--> \u001b[39m\u001b[32m520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fut\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dhana.Kumarasamy\\tech\\projects\\spl7\\wordle\\.venv\\Lib\\site-packages\\websockets\\asyncio\\connection.py:303\u001b[39m, in \u001b[36mConnection.recv\u001b[39m\u001b[34m(self, decode)\u001b[39m\n\u001b[32m    256\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    257\u001b[39m \u001b[33;03mReceive the next message.\u001b[39;00m\n\u001b[32m    258\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    300\u001b[39m \n\u001b[32m    301\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    302\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m303\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recv_messages.get(decode)\n\u001b[32m    304\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m:\n\u001b[32m    305\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dhana.Kumarasamy\\tech\\projects\\spl7\\wordle\\.venv\\Lib\\site-packages\\websockets\\asyncio\\messages.py:159\u001b[39m, in \u001b[36mAssembler.get\u001b[39m\u001b[34m(self, decode)\u001b[39m\n\u001b[32m    154\u001b[39m \u001b[38;5;66;03m# Locking with get_in_progress prevents concurrent execution\u001b[39;00m\n\u001b[32m    155\u001b[39m \u001b[38;5;66;03m# until get() fetches a complete message or is canceled.\u001b[39;00m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    158\u001b[39m     \u001b[38;5;66;03m# First frame\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m     frame = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.frames.get(\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.closed)\n\u001b[32m    160\u001b[39m     \u001b[38;5;28mself\u001b[39m.maybe_resume()\n\u001b[32m    161\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m frame.opcode \u001b[38;5;129;01mis\u001b[39;00m OP_TEXT \u001b[38;5;129;01mor\u001b[39;00m frame.opcode \u001b[38;5;129;01mis\u001b[39;00m OP_BINARY\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dhana.Kumarasamy\\tech\\projects\\spl7\\wordle\\.venv\\Lib\\site-packages\\websockets\\asyncio\\messages.py:51\u001b[39m, in \u001b[36mSimpleQueue.get\u001b[39m\u001b[34m(self, block)\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;28mself\u001b[39m.get_waiter = \u001b[38;5;28mself\u001b[39m.loop.create_future()\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.get_waiter\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     53\u001b[39m     \u001b[38;5;28mself\u001b[39m.get_waiter.cancel()\n",
      "\u001b[31mCancelledError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Run it (infinite loop until you interrupt the cell)\n",
    "await connect_parse_respond_forever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e98f39-6c3b-4213-89d1-c0308e5ae554",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179bf8b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-bot (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
